{"ast":null,"code":"import { encode, prepare } from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport Dir from './dir.js';\nimport persist from './utils/persist.js';\nimport { createHAMT, Bucket } from 'hamt-sharding';\n\nclass DirSharded extends Dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  async *eachChildSeries() {\n    for await (const {\n      key,\n      value\n    } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n\n  async *flush(blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield { ...entry,\n        path: this.path\n      };\n    }\n  }\n\n}\n\nexport default DirSharded;\n\nasync function* flush(bucket, blockstore, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n\n    if (!child) {\n      continue;\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n    if (child instanceof Bucket) {\n      let shard;\n\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard;\n      }\n\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      });\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n\n      const label = labelPrefix + child.key;\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      });\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n\n      if (!value.cid) {\n        continue;\n      }\n\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      });\n      childrenSize += size;\n    }\n  }\n\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  };\n  const buffer = encode(prepare(node));\n  const cid = await persist(buffer, blockstore, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}","map":{"version":3,"sources":["/Users/g2musicgroup/Developer/NFT-starter/filecoin_nft_starter-main/node_modules/ipfs-unixfs-importer/esm/src/dir-sharded.js"],"names":["encode","prepare","UnixFS","Dir","persist","createHAMT","Bucket","DirSharded","constructor","props","options","_bucket","hashFn","hamtHashFn","bits","hamtBucketBits","put","name","value","get","childCount","leafCount","directChildrenCount","childrenCount","onlyChild","eachChildSeries","key","eachLeafSeries","child","flush","blockstore","entry","path","bucket","shardRoot","children","_children","links","childrenSize","i","length","labelPrefix","toString","toUpperCase","padStart","shard","subShard","Error","push","Name","Tsize","size","Hash","cid","dir","flushedDir","label","data","Uint8Array","from","bitField","reverse","type","fanout","tableSize","hashType","hamtHashCode","mtime","mode","node","Data","marshal","Links","buffer","unixfs"],"mappings":"AAAA,SACEA,MADF,EAEEC,OAFF,QAGO,cAHP;AAIA,SAASC,MAAT,QAAuB,aAAvB;AACA,OAAOC,GAAP,MAAgB,UAAhB;AACA,OAAOC,OAAP,MAAoB,oBAApB;AACA,SACEC,UADF,EAEEC,MAFF,QAGO,eAHP;;AAIA,MAAMC,UAAN,SAAyBJ,GAAzB,CAA6B;AAC3BK,EAAAA,WAAW,CAACC,KAAD,EAAQC,OAAR,EAAiB;AAC1B,UAAMD,KAAN,EAAaC,OAAb;AACA,SAAKC,OAAL,GAAeN,UAAU,CAAC;AACxBO,MAAAA,MAAM,EAAEF,OAAO,CAACG,UADQ;AAExBC,MAAAA,IAAI,EAAEJ,OAAO,CAACK;AAFU,KAAD,CAAzB;AAID;;AACQ,QAAHC,GAAG,CAACC,IAAD,EAAOC,KAAP,EAAc;AACrB,UAAM,KAAKP,OAAL,CAAaK,GAAb,CAAiBC,IAAjB,EAAuBC,KAAvB,CAAN;AACD;;AACDC,EAAAA,GAAG,CAACF,IAAD,EAAO;AACR,WAAO,KAAKN,OAAL,CAAaQ,GAAb,CAAiBF,IAAjB,CAAP;AACD;;AACDG,EAAAA,UAAU,GAAG;AACX,WAAO,KAAKT,OAAL,CAAaU,SAAb,EAAP;AACD;;AACDC,EAAAA,mBAAmB,GAAG;AACpB,WAAO,KAAKX,OAAL,CAAaY,aAAb,EAAP;AACD;;AACDC,EAAAA,SAAS,GAAG;AACV,WAAO,KAAKb,OAAL,CAAaa,SAAb,EAAP;AACD;;AACqB,SAAfC,eAAe,GAAG;AACvB,eAAW,MAAM;AAACC,MAAAA,GAAD;AAAMR,MAAAA;AAAN,KAAjB,IAAiC,KAAKP,OAAL,CAAagB,cAAb,EAAjC,EAAgE;AAC9D,YAAM;AACJD,QAAAA,GADI;AAEJE,QAAAA,KAAK,EAAEV;AAFH,OAAN;AAID;AACF;;AACW,SAALW,KAAK,CAACC,UAAD,EAAa;AACvB,eAAW,MAAMC,KAAjB,IAA0BF,KAAK,CAAC,KAAKlB,OAAN,EAAemB,UAAf,EAA2B,IAA3B,EAAiC,KAAKpB,OAAtC,CAA/B,EAA+E;AAC7E,YAAM,EACJ,GAAGqB,KADC;AAEJC,QAAAA,IAAI,EAAE,KAAKA;AAFP,OAAN;AAID;AACF;;AAtC0B;;AAwC7B,eAAezB,UAAf;;AACA,gBAAgBsB,KAAhB,CAAsBI,MAAtB,EAA8BH,UAA9B,EAA0CI,SAA1C,EAAqDxB,OAArD,EAA8D;AAC5D,QAAMyB,QAAQ,GAAGF,MAAM,CAACG,SAAxB;AACA,QAAMC,KAAK,GAAG,EAAd;AACA,MAAIC,YAAY,GAAG,CAAnB;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGJ,QAAQ,CAACK,MAA7B,EAAqCD,CAAC,EAAtC,EAA0C;AACxC,UAAMX,KAAK,GAAGO,QAAQ,CAAChB,GAAT,CAAaoB,CAAb,CAAd;;AACA,QAAI,CAACX,KAAL,EAAY;AACV;AACD;;AACD,UAAMa,WAAW,GAAGF,CAAC,CAACG,QAAF,CAAW,EAAX,EAAeC,WAAf,GAA6BC,QAA7B,CAAsC,CAAtC,EAAyC,GAAzC,CAApB;;AACA,QAAIhB,KAAK,YAAYtB,MAArB,EAA6B;AAC3B,UAAIuC,KAAJ;;AACA,iBAAW,MAAMC,QAAjB,IAA6B,MAAMjB,KAAK,CAACD,KAAD,EAAQE,UAAR,EAAoB,IAApB,EAA0BpB,OAA1B,CAAxC,EAA4E;AAC1EmC,QAAAA,KAAK,GAAGC,QAAR;AACD;;AACD,UAAI,CAACD,KAAL,EAAY;AACV,cAAM,IAAIE,KAAJ,CAAU,sDAAV,CAAN;AACD;;AACDV,MAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAER,WADG;AAETS,QAAAA,KAAK,EAAEL,KAAK,CAACM,IAFJ;AAGTC,QAAAA,IAAI,EAAEP,KAAK,CAACQ;AAHH,OAAX;AAKAf,MAAAA,YAAY,IAAIO,KAAK,CAACM,IAAtB;AACD,KAdD,MAcO,IAAI,OAAOvB,KAAK,CAACV,KAAN,CAAYW,KAAnB,KAA6B,UAAjC,EAA6C;AAClD,YAAMyB,GAAG,GAAG1B,KAAK,CAACV,KAAlB;AACA,UAAIqC,UAAJ;;AACA,iBAAW,MAAMxB,KAAjB,IAA0BuB,GAAG,CAACzB,KAAJ,CAAUC,UAAV,CAA1B,EAAiD;AAC/CyB,QAAAA,UAAU,GAAGxB,KAAb;AACA,cAAMwB,UAAN;AACD;;AACD,YAAMC,KAAK,GAAGf,WAAW,GAAGb,KAAK,CAACF,GAAlC;AACAW,MAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAEO,KADG;AAETN,QAAAA,KAAK,EAAEK,UAAU,CAACJ,IAFT;AAGTC,QAAAA,IAAI,EAAEG,UAAU,CAACF;AAHR,OAAX;AAKAf,MAAAA,YAAY,IAAIiB,UAAU,CAACJ,IAA3B;AACD,KAdM,MAcA;AACL,YAAMjC,KAAK,GAAGU,KAAK,CAACV,KAApB;;AACA,UAAI,CAACA,KAAK,CAACmC,GAAX,EAAgB;AACd;AACD;;AACD,YAAMG,KAAK,GAAGf,WAAW,GAAGb,KAAK,CAACF,GAAlC;AACA,YAAMyB,IAAI,GAAGjC,KAAK,CAACiC,IAAnB;AACAd,MAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAEO,KADG;AAETN,QAAAA,KAAK,EAAEC,IAFE;AAGTC,QAAAA,IAAI,EAAElC,KAAK,CAACmC;AAHH,OAAX;AAKAf,MAAAA,YAAY,IAAIa,IAAhB;AACD;AACF;;AACD,QAAMM,IAAI,GAAGC,UAAU,CAACC,IAAX,CAAgBxB,QAAQ,CAACyB,QAAT,GAAoBC,OAApB,EAAhB,CAAb;AACA,QAAMP,GAAG,GAAG,IAAIpD,MAAJ,CAAW;AACrB4D,IAAAA,IAAI,EAAE,wBADe;AAErBL,IAAAA,IAFqB;AAGrBM,IAAAA,MAAM,EAAE9B,MAAM,CAAC+B,SAAP,EAHa;AAIrBC,IAAAA,QAAQ,EAAEvD,OAAO,CAACwD,YAJG;AAKrBC,IAAAA,KAAK,EAAEjC,SAAS,IAAIA,SAAS,CAACiC,KALT;AAMrBC,IAAAA,IAAI,EAAElC,SAAS,IAAIA,SAAS,CAACkC;AANR,GAAX,CAAZ;AAQA,QAAMC,IAAI,GAAG;AACXC,IAAAA,IAAI,EAAEhB,GAAG,CAACiB,OAAJ,EADK;AAEXC,IAAAA,KAAK,EAAEnC;AAFI,GAAb;AAIA,QAAMoC,MAAM,GAAGzE,MAAM,CAACC,OAAO,CAACoE,IAAD,CAAR,CAArB;AACA,QAAMhB,GAAG,GAAG,MAAMjD,OAAO,CAACqE,MAAD,EAAS3C,UAAT,EAAqBpB,OAArB,CAAzB;AACA,QAAMyC,IAAI,GAAGsB,MAAM,CAACjC,MAAP,GAAgBF,YAA7B;AACA,QAAM;AACJe,IAAAA,GADI;AAEJqB,IAAAA,MAAM,EAAEpB,GAFJ;AAGJH,IAAAA;AAHI,GAAN;AAKD","sourcesContent":["import {\n  encode,\n  prepare\n} from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport Dir from './dir.js';\nimport persist from './utils/persist.js';\nimport {\n  createHAMT,\n  Bucket\n} from 'hamt-sharding';\nclass DirSharded extends Dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n  get(name) {\n    return this._bucket.get(name);\n  }\n  childCount() {\n    return this._bucket.leafCount();\n  }\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n  async *eachChildSeries() {\n    for await (const {key, value} of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n  async *flush(blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield {\n        ...entry,\n        path: this.path\n      };\n    }\n  }\n}\nexport default DirSharded;\nasync function* flush(bucket, blockstore, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n    if (!child) {\n      continue;\n    }\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n    if (child instanceof Bucket) {\n      let shard;\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard;\n      }\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      });\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n      const label = labelPrefix + child.key;\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      });\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n      if (!value.cid) {\n        continue;\n      }\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      });\n      childrenSize += size;\n    }\n  }\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  };\n  const buffer = encode(prepare(node));\n  const cid = await persist(buffer, blockstore, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}"]},"metadata":{},"sourceType":"module"}